{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "from sssd.core.model_specs import setup_model, MASK_FN\n",
    "from sssd.utils.utils import (\n",
    "    calc_diffusion_hyperparams,\n",
    "    sampling,\n",
    "    std_normal\n",
    ")\n",
    "from sssd.core.imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "from sssd.core.layers.s4.s4_layer import S4Layer\n",
    "from sssd.core.utils import calc_diffusion_step_embedding\n",
    "from sssd.data.generator import ArDataGenerator\n",
    "from sssd.data.dataloader import ArDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc47aed",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_coefs = [0.8]\n",
    "series_length = 128\n",
    "season_period = 12\n",
    "\n",
    "# Generate data with intercept (mean = 3)\n",
    "data_with_intercept = ArDataGenerator(ar_coefs, series_length, std=5, intercept=100, season_period=season_period).generate()\n",
    "\n",
    "# Generate data without intercept (mean = 0)\n",
    "data_without_intercept = ArDataGenerator(ar_coefs, series_length, std=5, season_period=season_period).generate()\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(data_with_intercept, label=\"With Intercept (Mean = 3, Std = 5)\")\n",
    "plt.plot(data_without_intercept, label=\"Without Intercept (Mean = 0, Std = 5)\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"AR Process with and Without Intercept\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28831aa3",
   "metadata": {},
   "source": [
    "## Simulation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13df006",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_series = 1024\n",
    "coefficients = [0.8] \n",
    "series_length = 128\n",
    "std = 1\n",
    "intercept = 100\n",
    "season = 12\n",
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_workers = 4\n",
    "training_rate = 0.8\n",
    "seeds = list(range(num_series))\n",
    "\n",
    "data_loader = ArDataLoader(\n",
    "    coefficients,\n",
    "    num_series,\n",
    "    series_length,\n",
    "    std,\n",
    "    intercept,\n",
    "    season,\n",
    "    batch_size,\n",
    "    device,\n",
    "    num_workers,\n",
    "    training_rate,\n",
    "    seeds,\n",
    ")\n",
    "\n",
    "train_loader = data_loader.train_dataloader\n",
    "test_loader = data_loader.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/model.yaml\", \"rt\") as f:\n",
    "    model_config = yaml.safe_load(f.read())\n",
    "with open(\"../configs/training.yaml\", \"rt\") as f:\n",
    "    training_config = yaml.safe_load(f.read())\n",
    "\n",
    "with open(\"../configs/inference.yaml\", \"rt\") as f:\n",
    "    inference_config = yaml.safe_load(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mask(batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Update mask based on the given batch.\"\"\"\n",
    "    transposed_mask = MASK_FN[\"forecast\"](batch[0], 24)\n",
    "    return (\n",
    "        transposed_mask.permute(1, 0)\n",
    "        .repeat(batch.size()[0], 1, 1)\n",
    "        .to(device, dtype=torch.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a841ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SSSDS4Imputer(**model_config.get(\"wavenet\"), device=device)\n",
    "net = net.to(device)\n",
    "net = nn.DataParallel(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "diffusion_hyperparams = calc_diffusion_hyperparams(\n",
    "    **model_config[\"diffusion\"], device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loss(\n",
    "    model: torch.nn.Module,\n",
    "    training_data: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor],\n",
    "    diffusion_parameters: Dict[str, torch.Tensor],\n",
    "    generate_only_missing: int = 1,\n",
    "    device: str = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the training loss of epsilon and epsilon_theta.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        training_data (tuple): Training data tuple containing (time_series, condition, mask, loss_mask).\n",
    "        diffusion_parameters (dict): Dictionary of diffusion hyperparameters returned by calc_diffusion_hyperparams.\n",
    "                                     Note, the tensors need to be cuda tensors.\n",
    "        generate_only_missing (int): Flag to indicate whether to only generate missing values (default=1).\n",
    "        device (str): Device to run the computations on (default=\"cuda\").\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Training loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack diffusion hyperparameters\n",
    "    T, alpha_bar = diffusion_parameters[\"T\"], diffusion_parameters[\"Alpha_bar\"]\n",
    "\n",
    "    # Unpack training data\n",
    "    time_series, condition, mask, loss_mask = training_data\n",
    "\n",
    "    batch_size = time_series.shape[0]\n",
    "\n",
    "    # Sample random diffusion steps for each batch element\n",
    "    diffusion_steps = torch.randint(T, size=(batch_size, 1, 1)).to(device)\n",
    "    # Generate Gaussian noise, applying mask if specified\n",
    "    noise = (\n",
    "        time_series * mask.float()\n",
    "        + std_normal(time_series.shape, device) * (1 - mask).float()\n",
    "        if generate_only_missing\n",
    "        else std_normal(time_series.shape, device)\n",
    "    )\n",
    "\n",
    "    # Compute x_t from q(x_t|x_0)\n",
    "    transformed_series = (\n",
    "        torch.sqrt(alpha_bar[diffusion_steps]) * time_series\n",
    "        + torch.sqrt(1 - alpha_bar[diffusion_steps]) * noise\n",
    "    )\n",
    "\n",
    "    # Predict epsilon according to epsilon_theta\n",
    "    epsilon_theta = model(\n",
    "        (transformed_series, condition, mask, diffusion_steps.view(batch_size, 1))\n",
    "    )\n",
    "\n",
    "    # Compute loss\n",
    "    if generate_only_missing:\n",
    "        return nn.MSELoss()(epsilon_theta[loss_mask], noise[loss_mask])#, epsilon_theta[loss_mask], noise[loss_mask]\n",
    "    else:\n",
    "        return nn.MSELoss()(epsilon_theta, noise)#, epsilon_theta[loss_mask], noise[loss_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d262e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ec660",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs = 100\n",
    "for epoch in range(epochs):  # Train for 100 epochs (0-indexed)\n",
    "    epoch_loss = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}\") as pbar:\n",
    "        for batch in pbar:\n",
    "            batch = batch.to(device)\n",
    "            mask = update_mask(batch)\n",
    "            loss_mask = ~mask.bool()\n",
    "\n",
    "            batch = batch.permute(0, 2, 1)\n",
    "            assert batch.size() == mask.size() == loss_mask.size()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = training_loss(\n",
    "                model=net,\n",
    "                training_data=(batch, batch, mask, loss_mask),\n",
    "                diffusion_parameters=diffusion_hyperparams,\n",
    "                generate_only_missing=training_config.get(\"only_generate_missing\"),\n",
    "                device=device,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.cpu().detach().numpy() / len(train_loader)\n",
    "            pbar.set_postfix_str(f\"Loss: {epoch_loss:.4f}\")  # Update progress bar with loss\n",
    "    losses.append(epoch_loss)  # Append epoch loss to main list\n",
    "\n",
    "print(f\"Finished training for {len(losses)} epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bfc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(losses) + 1)\n",
    "\n",
    "# Plotting the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7480a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dh = diffusion_hyperparams\n",
    "T, Alpha, Alpha_bar, Sigma = _dh[\"T\"], _dh[\"Alpha\"], _dh[\"Alpha_bar\"], _dh[\"Sigma\"]\n",
    "batch = next(iter(test_loader))\n",
    "size = batch.shape\n",
    "cond = batch.to(device)\n",
    "x = std_normal(size, device) * 5 + 100\n",
    "only_generate_missing = 1\n",
    "mask = update_mask(batch).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming batch and generated_series are numpy arrays\n",
    "batch_mean = np.mean(batch.numpy(), axis=0).squeeze()\n",
    "generated_series_mean = np.mean(x.cpu().numpy(), axis=0).squeeze()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(series_length), batch_mean, label='Batch Mean')\n",
    "plt.plot(np.arange(series_length), generated_series_mean, label='Generated Series Mean')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71aea3",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a90c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result2 = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(test_loader, desc=f\"Epoch {epoch + 1}\") as pbar:\n",
    "        for batch in pbar:\n",
    "            mask = update_mask(batch)\n",
    "            batch = batch.permute(0, 2, 1)\n",
    "\n",
    "            generated_series, generated_series2 = sampling(\n",
    "                    net=net,\n",
    "                    size=batch.shape,\n",
    "                    diffusion_hyperparams=diffusion_hyperparams,\n",
    "                    cond=batch.to(device),\n",
    "                    mask=mask,\n",
    "                    only_generate_missing=0,\n",
    "                    device=device,\n",
    "                ) \n",
    "            \n",
    "        result.append(generated_series.detach().cpu().numpy().squeeze())\n",
    "        result2.append(generated_series2.detach().cpu().numpy().squeeze())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_result = np.stack(result, axis=0)\n",
    "pred = np.mean(stack_result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming batch and generated_series are numpy arrays\n",
    "batch_mean = np.mean(batch.numpy(), axis=0).squeeze()\n",
    "generated_series_mean = np.mean((pred.squeeze()), axis=0).squeeze()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(series_length), batch_mean, label='Batch Mean')\n",
    "plt.plot(np.arange(series_length), generated_series_mean, label='Generated Series Mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_result = np.stack(result, axis=0)\n",
    "pred = np.mean(stack_result, axis=0)\n",
    "pred_med  = np.median(stack_result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.stack(list(test_loader.dataset))\n",
    "target = test_data[:,-24:, :].transpose(0, 2, 1).squeeze()\n",
    "test_mean = np.mean(test_data[:,:168, :], axis=1)\n",
    "test_std = np.std(test_data[:,:168, :], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(target, pred))\n",
    "print(mean_squared_error(target, pred_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_percentage_error(target, pred))\n",
    "print(mean_absolute_percentage_error(target, pred_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613090f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate mean and standard deviation for each hour\n",
    "mean_target = np.mean(target, axis=0)\n",
    "std_target = np.std(target, axis=0)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "std_pred = np.std(pred, axis=0)\n",
    "\n",
    "# Generate hourly labels\n",
    "hours = np.arange(24)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot target mean with standard deviation band\n",
    "plt.plot(hours, mean_target, label='Target', marker='o')\n",
    "plt.fill_between(hours, mean_target - std_target, mean_target + std_target, alpha=0.2)\n",
    "\n",
    "# Plot prediction mean with standard deviation band\n",
    "plt.plot(hours, mean_pred, label='Prediction', marker='x')\n",
    "plt.fill_between(hours, mean_pred - std_pred, mean_pred + std_pred, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Comparison: Target vs Prediction')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(hours)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sssd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
