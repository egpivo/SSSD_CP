{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbf8e44-f345-49cd-a716-d04af20d209a",
   "metadata": {},
   "source": [
    "## Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480a143-39b8-4e25-996e-2f1bb7daa4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import yaml\n",
    "import boto3\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple, Dict, Union\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sssd.core.model_specs import setup_model, MASK_FN\n",
    "from sssd.core.layers.s4.s4_layer import S4Layer\n",
    "from sssd.core.utils import calc_diffusion_step_embedding\n",
    "from sssd.data.utils import get_dataloader\n",
    "from sssd.data.generator import ArDataGenerator\n",
    "from sssd.data.dataloader import ArDataLoader\n",
    "from sssd.utils.utils import (\n",
    "    calc_diffusion_hyperparams,\n",
    "    sampling,\n",
    "    std_normal,\n",
    "    find_repo_root,\n",
    "    load_yaml_file\n",
    ")\n",
    "from sssd.training.utils import training_loss\n",
    "from sssd.core.imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046602e-58d4-40ac-a46e-867704e78c05",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d0c4d-20bd-4111-bd75-d88916453d2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "std = 1\n",
    "intercept = 0\n",
    "\n",
    "num_series = 1024\n",
    "coefficients = [0.8]\n",
    "season = None\n",
    "series_length = 128\n",
    "season = 12\n",
    "batch_size = 128\n",
    "\n",
    "training_rate = 0.8\n",
    "epochs = 1\n",
    "inference_sample_size = 2\n",
    "seeds = list(range(num_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77307cc-7be9-422d-94fd-42e512fdf6cb",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13df006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = ArDataLoader(\n",
    "    coefficients,\n",
    "    num_series,\n",
    "    series_length,\n",
    "    std,\n",
    "    intercept,\n",
    "    season,\n",
    "    batch_size,\n",
    "    device,\n",
    "    num_workers,\n",
    "    training_rate,\n",
    "    seeds,\n",
    ")\n",
    "\n",
    "train_loader = data_loader.train_dataloader\n",
    "test_loader = data_loader.test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f596b-2d75-4861-9617-2b5709cf6a97",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "repo_root = find_repo_root(current_dir)\n",
    "\n",
    "configs_dir = os.path.join(repo_root, \"configs\")\n",
    "model_config_path = os.path.join(configs_dir, \"model.yaml\")\n",
    "training_config_path = os.path.join(configs_dir, \"training.yaml\")\n",
    "inference_config_path = os.path.join(configs_dir, \"inference.yaml\")\n",
    "\n",
    "# Load the configuration files\n",
    "model_config = load_yaml_file(model_config_path)\n",
    "training_config = load_yaml_file(training_config_path)\n",
    "inference_config = load_yaml_file(inference_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mask(batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Update mask based on the given batch.\"\"\"\n",
    "    transposed_mask = MASK_FN[\"forecast\"](batch[0], 24)\n",
    "    return (\n",
    "        transposed_mask.permute(1, 0)\n",
    "        .repeat(batch.size()[0], 1, 1)\n",
    "        .to(device, dtype=torch.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a841ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = SSSDS4Imputer(**model_config.get(\"wavenet\"), device=device)\n",
    "net = net.to(device)\n",
    "net = nn.DataParallel(net)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef4885-f687-466a-925c-3d7ec01d3e84",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ec660",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "diffusion_hyperparams = calc_diffusion_hyperparams(**model_config[\"diffusion\"], device=device)\n",
    "epoch_pbar = tqdm(range(epochs), desc=\"Training Epochs\")\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        mask = update_mask(batch)\n",
    "        loss_mask = ~mask.bool()\n",
    "\n",
    "        batch = batch.permute(0, 2, 1)\n",
    "        assert batch.size() == mask.size() == loss_mask.size()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = training_loss(\n",
    "            model=net,\n",
    "            loss_function=nn.MSELoss(),\n",
    "            training_data=(batch, batch, mask, loss_mask),\n",
    "            diffusion_parameters=diffusion_hyperparams,\n",
    "            generate_only_missing=training_config.get(\"only_generate_missing\"),\n",
    "            device=device,\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.cpu().detach().numpy() / len(train_loader)\n",
    "\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    epoch_pbar.set_postfix(loss=f'{epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "print(f\"Finished training for {len(losses)} epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bfc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), losses, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c4f9f-1e27-4f71-a08d-95d287448ed1",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a90c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "net.eval()\n",
    "\n",
    "# Iterate over each batch from the test_loader\n",
    "for batch in tqdm(test_loader, desc=\"Processing Batches\"):\n",
    "    batch = batch.to(device)\n",
    "    mask = update_mask(batch)\n",
    "    \n",
    "    # Ensure consistency in tensor operations\n",
    "    assert batch.is_cuda and mask.is_cuda, \"Tensors are not on the same device\"\n",
    "    assert batch.dtype == mask.dtype, \"Tensors do not have the same dtype\"\n",
    "    \n",
    "    batch = batch.permute(0, 2, 1)\n",
    "    \n",
    "    # Generate multiple samples for each batch\n",
    "    generated_samples = sampling(\n",
    "        net=net,\n",
    "        size=batch.shape,\n",
    "        diffusion_hyperparams=diffusion_hyperparams,\n",
    "        cond=batch,\n",
    "        mask=mask,\n",
    "        sample_size=inference_sample_size,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "\n",
    "    results.append(generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc1175-f423-4c49-b2e4-5ef25e490a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction = np.vstack([np.mean(result, axis=0) for result in results]).squeeze()\n",
    "std_prediction =np.vstack([np.std(result, axis=0) for result in results]).squeeze()\n",
    "mean_mean_prediction = np.mean(mean_prediction, axis=0)\n",
    "mean_std_prediction = np.mean(std_prediction, axis=0)\n",
    "\n",
    "median_prediction = np.vstack([np.median(result, axis=0) for result in results]).squeeze()\n",
    "\n",
    "test_data = torch.stack(list(test_loader.dataset)).squeeze()\n",
    "mean_true_values = np.mean(test_data.numpy(), axis=0)\n",
    "std_true_values = np.std(test_data.numpy(), axis=0)\n",
    "\n",
    "mse_mean_prediction = mean_squared_error(test_data[:,-24:], mean_prediction[:,-24:])\n",
    "mse_median_prediction = mean_squared_error(test_data[:,-24:], median_prediction[:,-24:])\n",
    "mape_mean_prediction = mean_absolute_percentage_error(test_data[:,-24:], mean_prediction[:,-24:])\n",
    "mape_median_prediction = mean_absolute_percentage_error(test_data[:,-24:], median_prediction[:,-24:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d7526-d870-483d-85bc-30f6d9b514d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = {\n",
    "    'Mean Squared Error': [mse_mean_prediction, mse_median_prediction],\n",
    "    'Mean Absolute Percentage Error': [mape_mean_prediction, mape_median_prediction]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(summary_results, index=['Mean Prediction', 'Median Prediction'])\n",
    "\n",
    "# Display the table\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be85cf-e16d-4fd4-affd-89edc3c05bad",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(series_length), mean_true_values, label='True Series Mean')\n",
    "plt.plot(np.arange(series_length), mean_mean_prediction, label='Generated Series Mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5acf33-04af-4aeb-b3a3-d50db37faa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_true_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613090f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "hours = range(24)\n",
    "\n",
    "# Plot true mean with standard deviation band\n",
    "plt.plot(hours, mean_true_values[-24:], label='Target', marker='o')\n",
    "plt.fill_between(hours, mean_true_values[-24:] - std_true_values[-24:], \n",
    "                 mean_true_values[-24:] + std_true_values[-24:], alpha=0.2)\n",
    "\n",
    "# Plot prediction mean with standard deviation band\n",
    "plt.plot(hours, mean_mean_prediction[-24:], label='Prediction', marker='x')\n",
    "plt.fill_between(hours, mean_mean_prediction[-24:] - mean_std_prediction[-24:], \n",
    "                 mean_mean_prediction[-24:] + mean_std_prediction[-24:], alpha=0.2)\n",
    "\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Comparison: Target vs Prediction')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(hours)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sssd",
   "language": "python",
   "name": "sssd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
