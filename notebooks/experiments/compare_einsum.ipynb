{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison of `torch.einsum` and `opt_einsum`*\n",
    "\n",
    "### *Why Compare?*\n",
    "\n",
    "When working with large tensors and complex contraction patterns, the performance of tensor contraction operations can significantly impact the overall efficiency of your code. `torch.einsum` and `opt_einsum` are two popular libraries for tensor contractions, but they have different optimization strategies and performance characteristics. By comparing their performance, you can choose the best library for your specific use case and optimize your code for better performance.\n",
    "\n",
    "### *Comparison Example*\n",
    "#### Contraction Pattern\n",
    "   $$\\sum_{n=1}^{N} \\sum_{h=1}^{H} \\sum_{m=1}^{M} A_{hmn} B_{hn} = C_{hm}$$\n",
    "   - e.g, `hmn,hn->hm`\n",
    "\n",
    "#### Tensor Size\n",
    "   - $H \\in \\{3, 10, 30, 100, 300, 1000\\}$\n",
    "   - $M \\in \\{4, 10, 30, 100, 300, 1000\\}$\n",
    "   - $N \\in \\{4, 10, 30, 100, 300, 1000\\}$\n",
    "#### Iteration\n",
    "   -  1000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "from opt_einsum import contract\n",
    "\n",
    "\n",
    "# Check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Define the tensor sizes\n",
    "H_values = [3, 10, 30, 100, 300, 1000]\n",
    "N_values = [4, 10, 30, 100, 300, 1000]\n",
    "iterations = 1000\n",
    "contraction_pattern = \"hmn,hn->hm\"\n",
    "\n",
    "# Initialize the timing results\n",
    "torch_einsum_cpu_times = []\n",
    "opt_einsum_cpu_times = []\n",
    "torch_einsum_gpu_times = []\n",
    "opt_einsum_gpu_times = []\n",
    "\n",
    "for H, N in zip(H_values, N_values):\n",
    "    A = torch.randn(H, N, N)\n",
    "    B = torch.randn(H, N)\n",
    "\n",
    "    # CPU test\n",
    "    torch_einsum_cpu_time = timeit.timeit(\n",
    "        lambda: torch.einsum(contraction_pattern, A, B),\n",
    "        number=iterations\n",
    "    )\n",
    "    opt_einsum_cpu_time = timeit.timeit(\n",
    "        lambda: contract(contraction_pattern, A, B),\n",
    "        number=iterations\n",
    "    )\n",
    "    torch_einsum_cpu_times.append(torch_einsum_cpu_time)\n",
    "    opt_einsum_cpu_times.append(opt_einsum_cpu_time)\n",
    "\n",
    "    # GPU test if CUDA is available\n",
    "    if use_cuda:\n",
    "        A_gpu = A.cuda()\n",
    "        B_gpu = B.cuda()\n",
    "        torch_einsum_gpu_time = timeit.timeit(\n",
    "            lambda: torch.einsum(contraction_pattern, A_gpu, B_gpu),\n",
    "            number=iterations\n",
    "        )\n",
    "        opt_einsum_gpu_time = timeit.timeit(\n",
    "            lambda: contract(contraction_pattern, A_gpu, B_gpu),\n",
    "            number=iterations\n",
    "        )\n",
    "        torch_einsum_gpu_times.append(torch_einsum_gpu_time)\n",
    "        opt_einsum_gpu_times.append(opt_einsum_gpu_time)\n",
    "    else:\n",
    "        torch_einsum_gpu_times.append(float('inf'))\n",
    "        opt_einsum_gpu_times.append(float('inf'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "torch_einsum_cpu_std = np.std(torch_einsum_cpu_times)\n",
    "opt_einsum_cpu_std = np.std(opt_einsum_cpu_times)\n",
    "torch_einsum_gpu_std = np.std(torch_einsum_gpu_times)\n",
    "opt_einsum_gpu_std = np.std(opt_einsum_gpu_times)\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define colors\n",
    "colors = sns.color_palette(\"husl\", 4)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.errorbar(\n",
    "    x=H_values,\n",
    "    y=torch_einsum_cpu_times,\n",
    "    yerr=torch_einsum_cpu_std,\n",
    "    label='Torch Einsum (CPU)',\n",
    "    capsize=5,\n",
    "    fmt='-o',\n",
    "    markersize=5,\n",
    "    color=colors[0]\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=H_values,\n",
    "    y=opt_einsum_cpu_times,\n",
    "    yerr=opt_einsum_cpu_std,\n",
    "    label='Opt Einsum (CPU)',\n",
    "    capsize=5,\n",
    "    fmt='-o',\n",
    "    markersize=5,\n",
    "    color=colors[1]\n",
    ")\n",
    "\n",
    "if use_cuda:\n",
    "    plt.errorbar(\n",
    "        x=H_values,\n",
    "        y=torch_einsum_gpu_times,\n",
    "        yerr=torch_einsum_gpu_std,\n",
    "        label='Torch Einsum (GPU)',\n",
    "        capsize=5,\n",
    "        fmt='-o',\n",
    "        markersize=5,\n",
    "        color=colors[2]\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        x=H_values,\n",
    "        y=opt_einsum_gpu_times,\n",
    "        yerr=opt_einsum_gpu_std,\n",
    "        label='Opt Einsum (GPU)',\n",
    "        capsize=5,\n",
    "        fmt='-o',\n",
    "        markersize=5,\n",
    "        color=colors[3]\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Tensor Size (H)', fontsize=12)\n",
    "plt.ylabel('Time (sec)', fontsize=12)\n",
    "plt.title('Performance Comparison', fontsize=14)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sssd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
