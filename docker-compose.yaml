version: "latest"
services:
  sssd:
    image: egpivo/sssd:latest
    volumes:
      - ./datasets/:/sssd/datasets
      - ./configs/:/sssd/configs
      - ./results:/sssd/results
    ports:
      - 8001:8080
    environment:
      PORT: 8080
      MODEL_CONFIG: "model.config"  # Path to the model configuration file in the `configs/` directory
      TRAINING_CONFIG: "training.config"  # Path to the training configuration file in the `configs/` directory. Leave empty ("") for no execution
      INFERENCE_CONFIG: "inference.config"  # Path to the inference configuration file in the `configs/` directory. Leave empty ("") for no execution
    shm_size: "2GB"  # Increase shared memory size for runtime if the number of GPUs increases
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]  # Specify the GPU ids, e.g., ["0", "2"]; or ["all"] for all GPUs
              capabilities: [gpu]
